# Shall We Build AI Decently?

Date: 2026.01.30 | Author: Zihan Ding

At the end of 2022, a senior AI researcher I once collaborated with said that *AGI had entered a countdown*.  
We came into a curse.

AI researchers have become crazily diligent—building new techniques, scaling data, models, and compute. This feels like a ruthless vortex, pulling intelligent minds into it, continuously absorbing humanity’s capacity for exploration in almost every other direction. Mixed into this vortex are money, reputation, and status—the desires that attract almost everyone.

Competition becomes more intense every day. People in frontier labs work overtime under enormous pressure, hoping to achieve bigger results, gain larger rewards, and win the competition. Attention keeps concentrating. Major companies race to invest more. Talent prices are pushed to nine or even ten figures. Model capabilities rise one after another.

Those researchers and engineers who struggled for years, studying quietly, working on cold benches, finally step into the spotlight and find ways to obtain outsized returns. Some actively choose to join this game; many more are dragged into it without mercy. The flood has already started to flow, and everyone will be pulled into the depths of the vortex.

**What are we actually creating?  AGI?**

Inside this system—OpenAI, Anthropic, Google, Chinese companies, and a large number of startups—everyone is rushing toward the mission of AGI. But if we look carefully, under short-term commercial competition, the products fall into mainly just two categories: things that attract attention, and tools for productivity.

The first category consists of products for *consumption*: search, chat, information services. Within existing commercial structures, they serve product marketing and advertising, and profits from usage maintain this balance.

The second category consists of products for *production*, those that help people make money. They expand individual capability and increase productivity, which in turn creates more intense competition. Companies empower individuals through AI tools. People feel the boost in their abilities, and at the same time fear falling behind in this competitive environment, so they rush to use them.

When everyone’s ability improves together, the structure of competition for social resources does not fundamentally change.

**We enter a ''death'' spiral.**

People obsessively build these tools, and at the same time everyone obsessively uses them, pushing competition even further. Does this process really bring happiness to individuals? Is this truly what we want to create?

The story of AGI begins to look like a religion. From core AI labs, to other departments, to other companies and industries, and finally to the general public—everyone is pulled into this god-building belief system.
We knew that AI will deliver indiscriminate shocks to all industries in the coming years, and countless people already live under the shadow of potential unemployment. I find it hard to imagine the social structure if this continues for decades—or perhaps I have imagined it, but it is too cruel to describe.

**Human capabilities become data; AI consumes data to replace them.**

When people, driven by social influence, begin to tentatively use these tools—from conversation, to calling functions, to delegating tasks, to granting device permissions, and eventually letting their lives follow its recommendations and plans—the system evolves.
From model, to agent, to an organization, and then to larger scales that continue to evolve on their own.
User data generated through experimentation is used to update the model to make it more engaging. When people delegate tasks, the companies designing these agents use the execution data to optimize task performance. As capabilities increase, task complexity grows, task spaces expand, and dependency deepens.
People rely on these systems to guide daily life and execute work, producing even more data for training.
Human abilities themselves become data, continuously injected into the system, allowing it to acquire the same abilities. At this point, human capability becomes replaceable. As long as it makes sense commercially, people who rely on these systems will gradually be replaced.


This iteration has no end in short future. Under capitalism, it is infinitely attractive to speculators, accelerating the spiral even faster. Every startup releases a new tool and easily raises large amounts of funding, participating in and reinforcing this game.
Companies that propose safeguards or ask society to slow down and think clearly directly conflict with the interests of every player in the game.
The players have already reached their own independent **equilibrium** strategies.

**Is there better equilibrium?**

I think everyone needs to seriously consider what AGI actually means, and what its payoff is for each individual.


If these tools do not maximize social well-being, or if our current frenzy over-consumes society itself, can we build them more decently?

What are we actually racing against?  
Time? Each other?

If we avoid internal social competition and slow down this process, could that lead to a better *correlated equilibrium*?


Should we return to the essence of why we create in the first place—  
to build AI decently, instead of creating a devil.
